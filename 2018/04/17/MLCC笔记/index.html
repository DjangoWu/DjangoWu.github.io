<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon.ico?v=5.1.4" color="#222">





  <meta name="keywords" content="Machine Learning," />










<meta name="description" content="问题构建 (Framing)：机器学习主要术语标签是我们要预测的事物，即简单线性回归中的 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。 特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征， 样本是指数据的特定实例：x。（我们采用粗体 x 表示它是一个矢量。）我们将样本分为以下两类">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="MLCC笔记">
<meta property="og:url" content="http://johnwu.top/2018/04/17/MLCC笔记/index.html">
<meta property="og:site_name" content="静默无声">
<meta property="og:description" content="问题构建 (Framing)：机器学习主要术语标签是我们要预测的事物，即简单线性回归中的 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。 特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征， 样本是指数据的特定实例：x。（我们采用粗体 x 表示它是一个矢量。）我们将样本分为以下两类">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvchwigmj20h807gweo.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvdmcuvej20j407eaal.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvdw26w7j20mx07w0tl.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfve2p8j4j20lf099js7.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvepp9g0j20ih06r74i.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvf0eog3j20gy08maa4.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvhvui3uj20iu09lwer.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvi8zzv7j20od09374o.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvfiznwhj20mn04zjrd.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvg62r1cj20h808rgmf.jpg">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvgck2gfj20gh0a9aa3.jpg">
<meta property="og:updated_time" content="2018-04-17T14:32:10.812Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MLCC笔记">
<meta name="twitter:description" content="问题构建 (Framing)：机器学习主要术语标签是我们要预测的事物，即简单线性回归中的 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。 特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征， 样本是指数据的特定实例：x。（我们采用粗体 x 表示它是一个矢量。）我们将样本分为以下两类">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/b91675efly1fqfvchwigmj20h807gweo.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://johnwu.top/2018/04/17/MLCC笔记/"/>





  <title>MLCC笔记 | 静默无声</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">静默无声</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Le vent se lève, il faut tenter de vivre</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-notes">
          <a href="/notes/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heart"></i> <br />
            
            札记
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://johnwu.top/2018/04/17/MLCC笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Wu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="静默无声">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">MLCC笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-04-17T22:30:39+08:00">
                2018-04-17
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-04-17T22:32:10+08:00">
                2018-04-17
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/04/17/MLCC笔记/" class="leancloud_visitors" data-flag-title="MLCC笔记">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6,737
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  23
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="问题构建-Framing-：机器学习主要术语"><a href="#问题构建-Framing-：机器学习主要术语" class="headerlink" title="问题构建 (Framing)：机器学习主要术语"></a>问题构建 (Framing)：机器学习主要术语</h2><p><strong>标签</strong>是我们要预测的事物，即简单线性回归中的 <code>y</code> 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。</p>
<p><strong>特征</strong>是输入变量，即简单线性回归中的 <code>x</code> 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征，</p>
<p><strong>样本</strong>是指数据的特定实例：<strong><code>x</code></strong>。（我们采用粗体 <strong><code>x</code></strong> 表示它是一个矢量。）我们将样本分为以下两类：</p>
<ul>
<li>有标签样本</li>
<li>无标签样本</li>
</ul>
<p><strong>模型</strong>定义了特征与标签之间的关系。例如，垃圾邮件检测模型可能会将某些特征与“垃圾邮件”紧密联系起来。</p>
<p>模型生命周期的两个阶段：</p>
<ul>
<li><strong>训练</strong>表示创建或<strong>学习</strong>模型。也就是说，您向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。</li>
<li><strong>推断</strong>表示将训练后的模型应用于无标签样本。</li>
</ul>
<p><strong>回归模型</strong>可预测连续值。例如，回归模型做出的预测可回答如下问题：</p>
<ul>
<li>加利福尼亚州一栋房产的价值是多少？</li>
<li>用户点击此广告的概率是多少？</li>
</ul>
<p><strong>分类模型</strong>可预测离散值。例如，分类模型做出的预测可回答如下问题：</p>
<ul>
<li>某个指定电子邮件是垃圾邮件还是非垃圾邮件？</li>
<li>这是一张狗、猫还是仓鼠图片？</li>
</ul>
<p><strong>训练</strong>模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为<strong>经验风险最小化</strong>。</p>
<p>损失是对糟糕预测的惩罚。也就是说，<strong>损失</strong>是一个数值，表示对于单个样本而言模型预测的准确程度。如果模型的预测完全准确，则损失为零，否则损失会较大。训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。</p>
<h2 id="降低损失"><a href="#降低损失" class="headerlink" title="降低损失"></a>降低损失</h2><p><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvchwigmj20h807gweo.jpg" alt=""></p>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>一种通过计算并且减小梯度将损失降至最低的技术，它以训练数据为条件，来计算损失相对于模型参数的梯度。通俗来说，梯度下降法以迭代方式调整参数，逐渐找到权重和偏差的最佳组合，从而将损失降至最低。</p>
<p>梯度下降法算法用梯度乘以一个称为<strong>学习速率</strong>（有时也称为<strong>步长</strong>）的标量，以确定下一个点的位置。</p>
<h3 id="随机梯度下降法（SGD）"><a href="#随机梯度下降法（SGD）" class="headerlink" title="随机梯度下降法（SGD）"></a>随机梯度下降法（SGD）</h3><p>在梯度下降法中，<strong>批量(batch)</strong>指的是用于在单次迭代中计算梯度的样本总数。</p>
<p><strong>随机梯度下降法 (SGD)</strong> ，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。</p>
<p><strong>小批量随机梯度下降法（小批量 SGD）</strong>是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 10-1000 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。</p>
<h2 id="泛化-Generalization"><a href="#泛化-Generalization" class="headerlink" title="泛化(Generalization)"></a>泛化(Generalization)</h2><ul>
<li><strong>训练集</strong> - 用于训练模型的子集。</li>
<li><strong>测试集</strong> - 用于测试模型的子集。</li>
</ul>
<h3 id="机器学习细则"><a href="#机器学习细则" class="headerlink" title="机器学习细则"></a>机器学习细则</h3><p>以下三项基本假设阐明了泛化：</p>
<ul>
<li>我们从分布中随机抽取<strong>独立同分布</strong> (i.i.d) 的样本。换言之，样本之间不会互相影响。（另一种解释：i.i.d. 是表示变量随机性的一种方式）。</li>
<li>分布是<strong>平稳的</strong>；即分布在数据集内不会发生变化。</li>
<li>我们从<strong>同一分布</strong>的数据划分中抽取样本。</li>
</ul>
<h2 id="表示法"><a href="#表示法" class="headerlink" title="表示法"></a>表示法</h2><h3 id="独热编码-One-Hot-Encoding"><a href="#独热编码-One-Hot-Encoding" class="headerlink" title="独热编码(One-Hot Encoding)"></a>独热编码(One-Hot Encoding)</h3><p>又可称为一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立独立的寄存器位，并且在任意时候，其中只有一位有效。</p>
<p><strong>例如</strong></p>
<blockquote>
<p>自然状态码为：000,001,010,011,100,101<br>独热编码为：000001,000010,000100,001000,010000,100000</p>
</blockquote>
<p>可以这样理解，对于每一个特征，如果它有m个可能值，那么经过独热编码后，就变成了m个二元特征（如成绩这个特征有好，中，差变成one-hot就是100, 010, 001）。并且，这些特征互斥，每次只有一个激活。因此，数据会变成稀疏的。</p>
<p>这样做的好处主要有：</p>
<blockquote>
<ol>
<li>解决了分类器不好处理属性数据的问题</li>
<li>在一定程度上也起到了扩充特征的作用</li>
</ol>
</blockquote>
<p><a href="https://blog.csdn.net/pipisorry/article/details/61193868" target="_blank" rel="noopener">参考</a></p>
<h3 id="表示-Representation-良好特征的特点"><a href="#表示-Representation-良好特征的特点" class="headerlink" title="表示(Representation): 良好特征的特点"></a>表示(Representation): 良好特征的特点</h3><blockquote>
<ol>
<li>避免很少使用的离散特征值</li>
<li>最好具有清晰明确的含义</li>
<li>不要将“神奇”的值与实际数据混为一谈<ul>
<li>解决神奇值，需要将该特征转换为两个特征:</li>
<li>一个特征只存储质量评分，不含神奇值</li>
<li>一个特征存储布尔值，表示是否提供了quality_rating。为该布尔值特征指定一个名称，例如：is_quality_rating_defined。</li>
</ul>
</li>
<li>考虑上游不稳定性</li>
</ol>
</blockquote>
<h3 id="表示-Representation-清理数据"><a href="#表示-Representation-清理数据" class="headerlink" title="表示(Representation): 清理数据"></a>表示(Representation): 清理数据</h3><h4 id="缩放特征值"><a href="#缩放特征值" class="headerlink" title="缩放特征值"></a>缩放特征值</h4><p><strong>缩放</strong>是指将浮点特征值从自然范围（例如 100 到 900）转换为标准范围（例如 0 到 1 或 -1 到 +1）。如果某个特征集只包含一个特征，则缩放可以提供的实际好处微乎其微或根本没有。不过，如果特征集包含多个特征，则缩放特征可以带来以下优势：</p>
<blockquote>
<ul>
<li>帮助梯度下降法更快速地收敛。</li>
<li>帮助避免“NaN 陷阱”。在这种陷阱中，模型中的一个数值变成 NaN（例如，当某个值在训练期间超出浮点精确率限制时），并且模型中的所有其他数值最终也会因数学运算而变成 NaN。</li>
<li>帮助模型为每个特征确定合适的权重。如果没有进行特征缩放，则模型会对范围较大的特征投入过多精力。</li>
</ul>
</blockquote>
<h4 id="处理离群特征值"><a href="#处理离群特征值" class="headerlink" title="处理离群特征值"></a>处理离群特征值</h4><ol>
<li>对数缩放</li>
<li>最大值限制</li>
</ol>
<h4 id="分箱"><a href="#分箱" class="headerlink" title="分箱"></a>分箱</h4><p>例如对经纬度样本使用整数进行分箱操作，另一种方法是按分位数分箱，这种方法确保每个桶内的样本数量是相等的。按分位数分箱无须担心离群值。</p>
<h4 id="清查"><a href="#清查" class="headerlink" title="清查"></a>清查</h4><p>在现实生活中，数据集中的很多样本是不可靠的，原因有以下一种或多种：</p>
<blockquote>
<ul>
<li>遗漏值。 例如，有人忘记为某个房屋的年龄输入值。</li>
<li>重复样本。 例如，服务器错误地将同一条记录上传了两次。</li>
<li>不良标签。 例如，有人错误地将一颗橡树的图片标记为枫树。</li>
<li>不良特征值。 例如，有人输入了多余的位数，或者温度计被遗落在太阳底下。</li>
</ul>
</blockquote>
<p>一旦检测到存在这些问题，您通常需要将相应样本从数据集中移除，从而“修正”不良样本。要检测遗漏值或重复样本，您可以编写一个简单的程序。检测不良特征值或标签可能会比较棘手。</p>
<p>除了检测各个不良样本之外，您还必须检测集合中的不良数据。直方图是一种用于可视化集合中数据的很好机制。此外，收集如下统计信息也会有所帮助：</p>
<blockquote>
<ul>
<li>最大值和最小值</li>
<li>均值和中间值</li>
<li>标准偏差</li>
</ul>
</blockquote>
<h4 id="了解数据"><a href="#了解数据" class="headerlink" title="了解数据"></a>了解数据</h4><p>遵循以下规则：</p>
<blockquote>
<ul>
<li>记住您预期的数据状态。</li>
<li>确认数据是否满足这些预期（或者您可以解释为何数据不满足预期）。</li>
<li>仔细检查训练数据是否与其他来源（例如信息中心）的数据一致。</li>
</ul>
</blockquote>
<p>像处理任何任务关键型代码一样谨慎处理您的数据。良好的机器学习依赖于良好的数据。</p>
<h2 id="特征组合-Feature-Crosses"><a href="#特征组合-Feature-Crosses" class="headerlink" title="特征组合(Feature Crosses)"></a>特征组合(Feature Crosses)</h2><p><strong>特征组合</strong>是指通过将两个或多个输入特征相乘来对特征空间中的非线性规律进行编码的合成特征。</p>
<p><strong>为什么要特征组合</strong></p>
<blockquote>
<ul>
<li>线性学习器可以很好地扩展到大量数据，例如vowpal-wabit、sofia-ml</li>
<li>不过，如果不使用特征组合，这些模型的表现度将受到限制 </li>
<li>使用特征组合 + 大量数据是学习高度复杂模型的一种有效策略<ul>
<li>神经网络可提供另一种策略</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="正则化：简单性"><a href="#正则化：简单性" class="headerlink" title="正则化：简单性"></a>正则化：简单性</h2><p>目的是为了防止过拟合</p>
<p>降低模型的复杂度：</p>
<ul>
<li>我们希望尽可能降低模型的复杂度</li>
<li>我们可以将这种想法纳入训练时所进行的优化中</li>
<li>经验风险最小化：<ul>
<li>只在减少训练误差： <code>minimize: Loss(Data|Model)</code></li>
<li>同时平衡复杂度： <code>minimize: Loss(Data|Model)+complexity(Model)</code> (一个是<strong>损失项</strong>，用于衡量模型与数据的拟合度，另一个是<strong>正则项</strong>，用于衡量模型复杂度)</li>
</ul>
</li>
</ul>
<p>课程介绍了两种衡量模型复杂度的常见方式：</p>
<ul>
<li>将模型复杂度作为模型中所有特征的权重的函数</li>
<li>将模型复杂度作为具有非零权重的特征总数的函数</li>
</ul>
<p>正则化：</p>
<ul>
<li>如何定义复杂度(模型)？</li>
<li>首选较小的权重</li>
<li>偏离将会产生成本</li>
<li>可以通过L<sub>2</sub><strong>正则化</strong>(也称为岭正则化)对这种想法编码<ul>
<li>复杂度(模型) = 权重的平方和</li>
<li>减少非常大的权重</li>
<li>对于线性模型：首选比较平缓的斜率</li>
<li>对贝叶斯先验概率：<ul>
<li>权重应该以0为中心</li>
<li>权重应该呈正太分布</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>L<sub>2</sub>正则化损失函数：<br><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvdmcuvej20j407eaal.jpg" alt=""></p>
<p>模型开发者通过以下方式来调整正则化项的整体影响：用正则化项的值乘以<strong>lambda</strong>(又称为<strong>正则化率</strong>)的标量。也就是执行下面运算：</p>
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><br>  <mtext>minimize(Loss(Data|Model)</mtext><br>  <mo>+</mo><br>  <mi>&#x03BB;<!-- λ --></mi><br>  <mtext>&#xA0;complexity(Model))</mtext><br></math>

<p>执行 L2 正则化对模型具有以下影响：</p>
<ul>
<li>使权重值接近于 0（但并非正好为 0）</li>
<li>使权重的平均值接近于 0，且呈正态（钟形曲线或高斯曲线）分布。</li>
</ul>
<p>增加lambda值将增强正则化效果，降低lambda的值往往会得到较为平缓的直方图(权重频率/权重值)</p>
<p>在选择 lambda 值时，目标是在简单化和训练数据拟合之间达到适当的平衡：</p>
<ul>
<li>如果您的 lambda 值过高，则模型会非常简单，但是您将面临数据欠拟合的风险。您的模型将无法从训练数据中获得足够的信息来做出有用的预测。</li>
<li>如果您的 lambda 值过低，则模型会比较复杂，并且您将面临数据过拟合的风险。您的模型将因获得过多训练数据特点方面的信息而无法泛化到新数据。</li>
</ul>
<blockquote>
<p>注意：将 lambda 设为 0 可彻底取消正则化。 在这种情况下，训练的唯一目的将是最小化损失，而这样做会使过拟合的风险达到最高。</p>
</blockquote>
<h2 id="逻辑回归-Logistic-Regression"><a href="#逻辑回归-Logistic-Regression" class="headerlink" title="逻辑回归(Logistic Regression)"></a>逻辑回归(Logistic Regression)</h2><p>逻辑回归：</p>
<ul>
<li>许多问题需要将概率估算值作为输出</li>
<li>输入<strong>逻辑回归</strong></li>
<li>很方便，因为概率估算值已经过<strong>校准</strong><ul>
<li>例如，p(待出售房屋) * 价格 = 预期价格</li>
</ul>
</li>
<li>此外，它在我们需要二元分类时非常有用<ul>
<li>垃圾邮件或非垃圾邮件？-&gt; p(垃圾邮件)</li>
</ul>
</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvdw26w7j20mx07w0tl.jpg" alt=""><br><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfve2p8j4j20lf099js7.jpg" alt=""></p>
<p>逻辑回归和正则化：</p>
<ul>
<li>正则化对于逻辑回归而言至关重要<ul>
<li>记住渐近线</li>
<li>它会不断尝试促使损失在高纬度空间内达到0</li>
</ul>
</li>
<li>以下两个策略尤为重要<ul>
<li><strong>L<sub>2</sub>正则化</strong>(也称为L<sub>2</sub>权重衰减) - 用于降低超大权重</li>
<li><strong>早停法</strong> - 用于限制训练步数或学习速率</li>
</ul>
</li>
</ul>
<p>线性逻辑回归</p>
<ul>
<li>线性逻辑回归极其高效<ul>
<li>超快的训练速度和较短的预测时间</li>
<li>短模型/宽度模型占用大量RAM</li>
</ul>
</li>
</ul>
<p>总结：</p>
<ul>
<li>逻辑回归模型会生成概率</li>
<li>对数损失函数是逻辑回归的损失函数</li>
<li>逻辑回归被很多从业者广泛使用</li>
</ul>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>如何评估分类模型：<br>评估标准：准确率(正确预测所占比例)</p>
<p>准确率可能存在误导性：</p>
<ul>
<li>最常是在不同类型的错误具有不同代价时</li>
<li>典型情况包括分类不平衡，即正类别或负类别极其罕见时</li>
</ul>
<p>真正例和假正例<br>TP = 真正例，TN = 真负例， FP = 假正例， FN = 假负例<br><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvepp9g0j20ih06r74i.jpg" alt=""></p>
<h3 id="评估指标：精确率和召回率"><a href="#评估指标：精确率和召回率" class="headerlink" title="评估指标：精确率和召回率"></a>评估指标：精确率和召回率</h3><ul>
<li><strong>精确率</strong>：(真正例次数)/(所有正类别预测次数) = TP / (TP + FP)<ul>
<li>当模型的预测为“正”类别时，预测正确吗？</li>
<li>直觉：模型是否过于频繁地提醒说“狼来了”？</li>
</ul>
</li>
<li><strong>召回率</strong>：(真正例次数)/(所有实际类别数) = TP / (TP + FN)<ul>
<li>在所有可能的正类别中，模型正确地识别出了多少？</li>
<li>直觉：是否漏掉了任何“狼来了”的情况？<blockquote>
<p>要全面评估模型的有效性，必须同时检查精确率和召回率，但是，精确率和召回率往往是此消彼长的情况。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h3 id="ROC曲线"><a href="#ROC曲线" class="headerlink" title="ROC曲线"></a>ROC曲线</h3><p><strong>ROC曲线(接收者操作特征曲线)</strong>是一种显示分类模型在所有分类阈值下的效果的图标。</p>
<ul>
<li>真正例率(TPR) = TP / (TP + FN)</li>
<li>假正例率(FPR) = FP / (FP + TN)</li>
</ul>
<p><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvf0eog3j20gy08maa4.jpg" alt=""><br>评估指标:曲线下面积(Area Under Curve)<br>(看做模型将某个随机正类别样本排列在某个随机负类别样本之上的概率)</p>
<p>实用原因：</p>
<ul>
<li>曲线下面积的<strong>尺度不变</strong>，它测量预测的排名情况，而不是测量其绝对值</li>
<li>曲线下面积的<strong>分类阈值不变</strong>，它测量模型预测的质量，而不考虑所选的分类阈值</li>
</ul>
<p>局限性：</p>
<ul>
<li><strong>并非总是希望尺度不变</strong>，例如：有时需要被良好校准的概率输出，而曲线下面积无法告诉我们这一结果。</li>
<li><strong>并非总是希望分类阈值不变</strong>， 在假负例与假正例的代价存在较大差异的情况下，尽量减少一种类型的分类错误可能至关重要。例如，在进行垃圾邮件检测时，您可能希望优先考虑尽量减少假正例（即使这会导致假负例大幅增加）。对于此类优化，曲线下面积并非一个实用的指标。</li>
</ul>
<h3 id="预测偏差"><a href="#预测偏差" class="headerlink" title="预测偏差"></a>预测偏差</h3><p>逻辑回归预测应当无偏差。</p>
<ul>
<li>预测平均值 == 观察平均值<br>偏差是一个具有指示作用的值</li>
<li>仅仅是零偏差并不能说明系统中的一切都完美无缺</li>
<li>但偏差是一项非常实用的健全性检查项目</li>
<li>如果出现偏差，则说明存在问题：<ul>
<li>特征集不完整？</li>
<li>数据集混乱？</li>
<li>模型实现流水线中有错误？</li>
<li>训练样本有偏差？</li>
<li>正则化过强？</li>
</ul>
</li>
</ul>
<p>请勿实用校准层来修正偏差，而应在模型中予以修正</p>
<ul>
<li>校准修复的是症状，而不是原因</li>
<li>建立了一个更脆弱的系统，并且必须持续更新</li>
</ul>
<p>查看各部分数据是否存在偏差-这有助于指导如何进行改进。</p>
<h2 id="正则化：稀疏性"><a href="#正则化：稀疏性" class="headerlink" title="正则化：稀疏性"></a>正则化：稀疏性</h2><p><strong>注意</strong>：稀疏特征组合可能会大大增加特征空间<br>可能出现问题：</p>
<ul>
<li>模型大小(RAM)可能会变得庞大</li>
<li>“噪点”系数(导致过拟合)</li>
</ul>
<p>L<sub>1</sub>和L<sub>2</sub>采用不同的方式降低权重：</p>
<ul>
<li>L<sub>2</sub>会降低权重<sup>2</sup></li>
<li>L<sub>1</sub>会降低|权重|<br>因此，L<sub>2</sub>和L<sub>1</sub>具有不同的导数：</li>
<li>L<sub>2</sub>的导数为<code>2 * 权重</code></li>
<li>L<sub>1</sub>的导数为<code>k</code>(一个常数，其值与权值无关)</li>
</ul>
<blockquote>
<p>您可以将 L<sub>2</sub> 的导数的作用理解为每次移除权重的 x%。如 <a href="https://www.nctm.org/mathforum/" target="_blank" rel="noopener">Zeno</a> 所知，对于任意数字，即使按每次减去 x% 的幅度执行数十亿次减法计算，最后得出的值也绝不会正好为 0。（Zeno 不太熟悉浮点精度限制，它可能会使结果正好为 0。）总而言之，L<sub>2</sub> 通常不会使权重变为 0。<br>您可以将 L<sub>1</sub> 的导数的作用理解为每次从权重中减去一个常数。不过，由于减去的是绝对值，L<sub>1</sub> 在 0 处具有不连续性，这会导致与 0 相交的减法结果变为 0。例如，如果减法使权重从 +0.1 变为 -0.2，L<sub>1</sub> 便会将权重设为 0。就这样，L<sub>1</sub> 使权重变为 0 了。</p>
</blockquote>
<p>注意：L1正则化可能会使以下类型的特征权重正好为0：</p>
<blockquote>
<ol>
<li>信息缺乏的特征</li>
<li>不同程度的信息丰富的特征</li>
<li>与其他类似的信息丰富特征密切相关的信息丰富特征</li>
</ol>
</blockquote>
<h3 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L<sub>1</sub>正则化</h3><p>会对L<sub>0</sub>权重的范数进行惩罚</p>
<ul>
<li>非凸优化；NP困难<br>比较放松的L<sub>1</sub>正则化：</li>
<li>对绝对值(权重)之和进行惩罚</li>
<li>凸优化问题</li>
<li>和L<sub>2</sub>不同，L<sub>1</sub>鼓励稀疏性</li>
</ul>
<h2 id="神经网络-Neural-Networks"><a href="#神经网络-Neural-Networks" class="headerlink" title="神经网络(Neural Networks)"></a>神经网络(Neural Networks)</h2><p>神经网络标准组件：</p>
<ul>
<li>一组节点，类似于神经元，位于层中</li>
<li>一组权重，表示每个神经网络层与其下方的层之间的关系。下方的层可能是另一个神经网络层，也可能是其他类型的层</li>
<li>一组偏差，每个节点一个偏差</li>
<li>一个激活函数，对曾中每个节点的输出进行转换。不同的层可能拥有不同的激活函数<br>注意：神经网络不一定始终比特征组合好，但它的确可以提供适用于很多情形的灵活替代方案<br><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvhvui3uj20iu09lwer.jpg" alt=""><br><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvi8zzv7j20od09374o.jpg" alt=""></li>
</ul>
<h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p>注意：</p>
<ul>
<li>梯度很重要<ul>
<li>如果它是可微的，则我们也许能够对其进行学习</li>
</ul>
</li>
<li>梯度可能消失<ul>
<li>每个额外的层都会依次降低信噪比</li>
<li>Relu在这里很有用</li>
</ul>
</li>
<li>梯度可能会爆炸<ul>
<li>学习速率在这里很重要</li>
<li>批标准化(实用按钮)可以提供帮助</li>
</ul>
</li>
<li>Relu层可能会消失<ul>
<li>保持冷静，并降低您的学习速率</li>
</ul>
</li>
</ul>
<h3 id="标准化特征值"><a href="#标准化特征值" class="headerlink" title="标准化特征值"></a>标准化特征值</h3><ul>
<li>我们希望特征具有合理的范围<ul>
<li>大致以0位中心，<code>[-1, 1]</code>的范围通常效果比较好</li>
<li>有助于梯度下降法收敛；避免NaN陷阱</li>
<li>避免离群值也会有帮助</li>
</ul>
</li>
<li>可以使用一些标准方法<ul>
<li>线性缩放</li>
<li>为最大值和最小值设定硬性上下限(截断)</li>
<li>对数缩放</li>
</ul>
</li>
</ul>
<h3 id="丢弃正则化"><a href="#丢弃正则化" class="headerlink" title="丢弃正则化"></a>丢弃正则化</h3><ul>
<li>丢弃：另一种正则化形式，对神经网络很有用</li>
<li>工作原理是，在一个梯度步长中随机“丢弃”网络的单元<ul>
<li>有一个可用于集成学习此处的模型的连接</li>
</ul>
</li>
<li>丢弃的越多，正则化效果就越强<ul>
<li>0.0 = 无丢弃正则化</li>
<li>1.0 = 丢弃所有内容！学不到任何规律</li>
<li>中间值更有用</li>
</ul>
</li>
</ul>
<h3 id="多类别神经网络"><a href="#多类别神经网络" class="headerlink" title="多类别神经网络"></a>多类别神经网络</h3><p><strong>SoftMax方程式</strong><br><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvfiznwhj20mn04zjrd.jpg" alt=""></p>
<p><strong>SoftMax多类别</strong></p>
<ul>
<li>添加了附加限制：要求所有一对多节点的输出总和为1.0</li>
<li>附加限制有助于快速训练收敛</li>
<li>另外，允许输出解析为概率</li>
</ul>
<p><strong>SoftMax选项</strong></p>
<ul>
<li>完整SoftMax<ul>
<li>暴力破解；针对所有类别进行计算</li>
</ul>
</li>
<li>候选采样<ul>
<li>针对所有正类别标签进行计算，但仅针对负类别标签的随机样本进行计算</li>
</ul>
</li>
</ul>
<p>何时使用何种类别？</p>
<ul>
<li>多类别单一标签分类：<ul>
<li>一个样本可能只是一个类别的成员</li>
<li>类别互斥这一限制是有用的结构</li>
<li>有助于在损失中对此进行编码</li>
<li>将一个softmax损失用于所有可能的类别</li>
</ul>
</li>
<li>多分类多标签分类：<ul>
<li>一个样本可能是多个类别的成员</li>
<li>无需对类别成员资格设定额外的限制</li>
<li>将一个逻辑回归损失用于每个可能的类别</li>
</ul>
</li>
</ul>
<h2 id="嵌套-Embedding"><a href="#嵌套-Embedding" class="headerlink" title="嵌套(Embedding)"></a>嵌套(Embedding)</h2><p><strong>嵌套</strong>是一种相对低维的空间，您可以将高维矢量映射到这种低维空间里。通过使用嵌套，可以让在大型输入（比如代表字词的稀疏矢量）上进行机器学习变得更加容易。在理想情况下，嵌套可以将语义上相似的不同输入映射到嵌套空间里的邻近处，以此来捕获输入的语义。一个模型学习到的嵌套，也可以被其他模型重用。</p>
<h3 id="协同过滤的目的"><a href="#协同过滤的目的" class="headerlink" title="协同过滤的目的"></a>协同过滤的目的</h3><p><strong>协同过滤</strong>是一项可以预测用户兴趣(根据很多其他用户的兴趣)的任务。</p>
<h3 id="分类输入数据"><a href="#分类输入数据" class="headerlink" title="分类输入数据"></a>分类输入数据</h3><p><strong>分类数据</strong>是指用于表示一组有限选项中的一个或多个离散项的输入特征。例如，它可以是某用户观看过的一组影片，某文档中使用的一系列单词，或某人从事的职业。<br>分类数据的最高效表示方式是使用<strong>稀疏张量</strong>(一种含有极少非零元素的张量)。</p>
<h3 id="转换到低维度空间"><a href="#转换到低维度空间" class="headerlink" title="转换到低维度空间"></a>转换到低维度空间</h3><p>解决稀疏输入数据的核心问题，可以将高维度数据映射到低维度空间。</p>
<h3 id="获取嵌套"><a href="#获取嵌套" class="headerlink" title="获取嵌套"></a>获取嵌套</h3><ol>
<li>标准降维技术：如PCA</li>
<li>Word2vec：基于<strong>分布假设</strong>，将语义上相似的字词映射到几何图形上邻近的嵌套矢量。</li>
<li>将嵌套训练位大型模型的一部分：<br><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvg62r1cj20h808rgmf.jpg" alt=""></li>
</ol>
<p>在深度网络中学习嵌套</p>
<ul>
<li>无需单独的训练过程，也就是说，嵌套层只是隐藏层，每个维度一个单元</li>
<li>监督式信息（例如用户观看了两部相同的影片）针对所需任务调整学到的嵌套</li>
<li>隐藏单元直观地发现如何整理 d 维空间中的各项，才能最大限度地优化最终目标</li>
</ul>
<p>选择嵌套维度个数</p>
<ul>
<li>嵌套维度的个数越多，越能准确地表示输入值之间的关系</li>
<li>不过，维度个数越多，过拟合的可能性就越高，训练速度也会越慢</li>
<li>经验法则（一个不错的起点，但应使用验证数据进行微调）：</li>
</ul>
<p>嵌套充当工具</p>
<ul>
<li>嵌套会以相似内容彼此靠近的方式将各项内容（如影片、文字等）映射到低维实矢量</li>
<li>嵌套也可应用于密集数据（如音频），以创建有意义的相似度指标</li>
<li>联合嵌套多种类型的数据（如文字、图片、音频等），以定义这些数据之间的相似度</li>
</ul>
<h2 id="机器学习工程"><a href="#机器学习工程" class="headerlink" title="机器学习工程"></a>机器学习工程</h2><h3 id="生产环境及其学习系统-Production-ML-Systems"><a href="#生产环境及其学习系统-Production-ML-Systems" class="headerlink" title="生产环境及其学习系统(Production ML Systems)"></a>生产环境及其学习系统(Production ML Systems)</h3><p><img src="http://ww1.sinaimg.cn/large/b91675efly1fqfvgck2gfj20gh0a9aa3.jpg" alt=""></p>
<p>系统级组件：无须自行构建所有内容</p>
<ul>
<li>尽可能重复使用常规机器学习系统组件。</li>
<li>Google CloudML 解决方案包括 Dataflow 和 TF Serving</li>
<li>您还可以在 Spark、Hadoop 等其他平台中找到组件</li>
<li>如何知道自己需要哪些组件？<ul>
<li>了解机器学习系统的一些范例及其要求</li>
</ul>
</li>
</ul>
<h3 id="静态训练与动态训练-Static-vs-Dynamic-Training"><a href="#静态训练与动态训练-Static-vs-Dynamic-Training" class="headerlink" title="静态训练与动态训练(Static vs. Dynamic Training)"></a>静态训练与动态训练(Static vs. Dynamic Training)</h3><ul>
<li><p><strong>静态模型</strong>采用离线训练方式。也就是说，我们只训练模型一次，然后使用训练后的模型一段时间。</p>
<ul>
<li>易于构建和测试 - 使用批量训练和测试，对其进行迭代，直到达到良好效果。</li>
<li>仍然需要对输入进行监控</li>
<li>模型容易过时</li>
</ul>
</li>
<li><p><strong>动态模型</strong>采用在线训练方式。也就是说，数据会不断进入系统，我们通过不断地更新系统将这些数据整合到模型中。</p>
<ul>
<li>随着时间推移不断为训练数据注入新数据，定期同步更新版本。</li>
<li>使用渐进式验证，而不是批量训练和测试</li>
<li>需要监控、模型回滚和数据隔离功能</li>
<li>会根据变化作出相应调整，避免了过时问题</li>
</ul>
</li>
</ul>
<h3 id="静态推理与动态推理-Static-vs-Dynamic-Inference"><a href="#静态推理与动态推理-Static-vs-Dynamic-Inference" class="headerlink" title="静态推理与动态推理 (Static vs. Dynamic Inference)"></a>静态推理与动态推理 (Static vs. Dynamic Inference)</h3><ul>
<li><p><strong>离线推理</strong>，指的是使用 MapReduce 或类似方法批量进行所有可能的预测。然后，将预测记录到 SSTable 或 Bigtable 中，并将它们提供给一个缓存/查询表。</p>
<ul>
<li>优点：不需要过多担心推理成本。</li>
<li>优点：可以使用批量方法。</li>
<li>优点：可以在推送之前对数据预测执行后期验证。</li>
<li>缺点：只能对我们知晓的数据进行预测，不适用于存在长尾的情况。</li>
<li>缺点：更新可能延迟数小时或数天。</li>
</ul>
</li>
<li><p><strong>在线推理</strong>，指的是使用服务器根据需要进行预测。</p>
<ul>
<li>优点：可在新项目加入时对其进行预测，非常适合存在长尾的情况。</li>
<li>缺点：计算量非常大，对延迟较为敏感，可能会限制模型的复杂度。</li>
<li>缺点：监控需求更多。</li>
</ul>
</li>
</ul>
<h3 id="数据依赖关系"><a href="#数据依赖关系" class="headerlink" title="数据依赖关系"></a>数据依赖关系</h3><p>特征管理</p>
<ul>
<li>输入数据（特征）决定机器学习系统的行为。<ul>
<li>我们可以针对软件库编写单元测试，但数据呢？</li>
</ul>
</li>
<li>选择输入信号时要谨慎。<ul>
<li>甚至比决定要依赖哪个软件库时更谨慎吗？</li>
</ul>
</li>
</ul>
<p>对输入数据提出的问题：</p>
<ul>
<li>可靠性<ul>
<li>信号不可用时会出现什么情况？您知道吗？例如：<ul>
<li>信号是否来自因负载过重而崩溃的服务器？</li>
<li>信号是否来自每年 8 月去度假的人群？</li>
</ul>
</li>
</ul>
</li>
<li>版本控制<ul>
<li>计算此信号的系统是否发生过变化？多久一次？会出现什么情况？如果是：<ul>
<li>多久一次？</li>
<li>您如何知道系统发生变化的时间？</li>
</ul>
</li>
</ul>
</li>
<li>必要性<ul>
<li>信号的实用性是否能证明值得添加此信号？</li>
</ul>
</li>
<li>相关性<ul>
<li>是否有任何输入信号密不可分，以至于需要采取额外策略来梳理它们？</li>
</ul>
</li>
<li>反馈环<ul>
<li>哪个输入信号可能会受到我的模型输出的影响？</li>
</ul>
</li>
</ul>
<h2 id="有效的机器学习准则"><a href="#有效的机器学习准则" class="headerlink" title="有效的机器学习准则"></a>有效的机器学习准则</h2><ul>
<li>确保第一个模型简单易用。</li>
<li>着重确保数据管道的正确性。</li>
<li>使用简单且可观察的指标进行训练和评估。</li>
<li>拥有并监控您的输入特征。</li>
<li>将您的模型配置视为代码：进行审核并记录在案。</li>
<li>记下所有实验的结果，尤其是“失败”的结果。</li>
</ul>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="John Wu 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="John Wu 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    John Wu
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://johnwu.top/2018/04/17/MLCC笔记/" title="MLCC笔记">http://johnwu.top/2018/04/17/MLCC笔记/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag"><i class="fa fa-tag"></i> Machine Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/06/头号玩家-彩蛋普拉斯/" rel="next" title="头号玩家-彩蛋普拉斯">
                <i class="fa fa-chevron-left"></i> 头号玩家-彩蛋普拉斯
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMjk3Mi85NTM0"></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="John Wu" />
            
              <p class="site-author-name" itemprop="name">John Wu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#问题构建-Framing-：机器学习主要术语"><span class="nav-number">1.</span> <span class="nav-text">问题构建 (Framing)：机器学习主要术语</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#降低损失"><span class="nav-number">2.</span> <span class="nav-text">降低损失</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#梯度下降法"><span class="nav-number">2.1.</span> <span class="nav-text">梯度下降法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机梯度下降法（SGD）"><span class="nav-number">2.2.</span> <span class="nav-text">随机梯度下降法（SGD）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#泛化-Generalization"><span class="nav-number">3.</span> <span class="nav-text">泛化(Generalization)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#机器学习细则"><span class="nav-number">3.1.</span> <span class="nav-text">机器学习细则</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#表示法"><span class="nav-number">4.</span> <span class="nav-text">表示法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#独热编码-One-Hot-Encoding"><span class="nav-number">4.1.</span> <span class="nav-text">独热编码(One-Hot Encoding)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#表示-Representation-良好特征的特点"><span class="nav-number">4.2.</span> <span class="nav-text">表示(Representation): 良好特征的特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#表示-Representation-清理数据"><span class="nav-number">4.3.</span> <span class="nav-text">表示(Representation): 清理数据</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#缩放特征值"><span class="nav-number">4.3.1.</span> <span class="nav-text">缩放特征值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#处理离群特征值"><span class="nav-number">4.3.2.</span> <span class="nav-text">处理离群特征值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分箱"><span class="nav-number">4.3.3.</span> <span class="nav-text">分箱</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#清查"><span class="nav-number">4.3.4.</span> <span class="nav-text">清查</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#了解数据"><span class="nav-number">4.3.5.</span> <span class="nav-text">了解数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征组合-Feature-Crosses"><span class="nav-number">5.</span> <span class="nav-text">特征组合(Feature Crosses)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化：简单性"><span class="nav-number">6.</span> <span class="nav-text">正则化：简单性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归-Logistic-Regression"><span class="nav-number">7.</span> <span class="nav-text">逻辑回归(Logistic Regression)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类"><span class="nav-number">8.</span> <span class="nav-text">分类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#评估指标：精确率和召回率"><span class="nav-number">8.1.</span> <span class="nav-text">评估指标：精确率和召回率</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ROC曲线"><span class="nav-number">8.2.</span> <span class="nav-text">ROC曲线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#预测偏差"><span class="nav-number">8.3.</span> <span class="nav-text">预测偏差</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化：稀疏性"><span class="nav-number">9.</span> <span class="nav-text">正则化：稀疏性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#L1正则化"><span class="nav-number">9.1.</span> <span class="nav-text">L1正则化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络-Neural-Networks"><span class="nav-number">10.</span> <span class="nav-text">神经网络(Neural Networks)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#反向传播算法"><span class="nav-number">10.1.</span> <span class="nav-text">反向传播算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#标准化特征值"><span class="nav-number">10.2.</span> <span class="nav-text">标准化特征值</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#丢弃正则化"><span class="nav-number">10.3.</span> <span class="nav-text">丢弃正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#多类别神经网络"><span class="nav-number">10.4.</span> <span class="nav-text">多类别神经网络</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#嵌套-Embedding"><span class="nav-number">11.</span> <span class="nav-text">嵌套(Embedding)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#协同过滤的目的"><span class="nav-number">11.1.</span> <span class="nav-text">协同过滤的目的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类输入数据"><span class="nav-number">11.2.</span> <span class="nav-text">分类输入数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#转换到低维度空间"><span class="nav-number">11.3.</span> <span class="nav-text">转换到低维度空间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取嵌套"><span class="nav-number">11.4.</span> <span class="nav-text">获取嵌套</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#机器学习工程"><span class="nav-number">12.</span> <span class="nav-text">机器学习工程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#生产环境及其学习系统-Production-ML-Systems"><span class="nav-number">12.1.</span> <span class="nav-text">生产环境及其学习系统(Production ML Systems)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#静态训练与动态训练-Static-vs-Dynamic-Training"><span class="nav-number">12.2.</span> <span class="nav-text">静态训练与动态训练(Static vs. Dynamic Training)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#静态推理与动态推理-Static-vs-Dynamic-Inference"><span class="nav-number">12.3.</span> <span class="nav-text">静态推理与动态推理 (Static vs. Dynamic Inference)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据依赖关系"><span class="nav-number">12.4.</span> <span class="nav-text">数据依赖关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#有效的机器学习准则"><span class="nav-number">13.</span> <span class="nav-text">有效的机器学习准则</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Wu</span>

  
</div>


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  访客量:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

  



  <span class="post-meta-divider">|</span>
  <div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">总字数:28.8k</span>
  </div>





  




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("T60TnQLHC7COiEaV2eASnH5i-gzGzoHsz", "J8pQW9fKfPvm7hmuAMuaOS92");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  

  
  <script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.4"></script>
  <script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  

</body>
</html>
